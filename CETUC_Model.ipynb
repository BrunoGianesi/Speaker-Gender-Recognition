{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# df = pd.read_csv('data/CETUC_Features_data.csv')\n",
    "df = pd.read_csv('data/CETUC_Features_data.csv')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FileName  nobs        mean      skew  kurtosis  median   mode  \\\n",
       "0  F003-0616.wav    24  179.803922 -0.453233 -1.540090   205.0  115.0   \n",
       "1  F000-0823.wav    19  341.034577 -0.369143  0.038573   385.0  450.0   \n",
       "2  M009-0399.wav    29  164.397933  0.870210 -0.357093   120.0   15.0   \n",
       "3  F033-0492.wav    25  199.400000  0.323917 -1.207102   180.0    0.0   \n",
       "4  M029-0430.wav    24  196.577381  0.800063 -0.598391   180.0  145.0   \n",
       "\n",
       "          std         low   peak    q25     q75     iqr  Gender  \n",
       "0   48.533917  110.294118  240.0  115.0  220.00  105.00       0  \n",
       "1  164.184087   30.000000  695.0  252.5  447.50  195.00       0  \n",
       "2  155.589327    7.540057  530.0   15.0  225.00  210.00       1  \n",
       "3  188.384288    0.000000  575.0    0.0  370.00  370.00       0  \n",
       "4   56.700662  140.000000  320.0  145.0  238.75   93.75       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>nobs</th>\n",
       "      <th>mean</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>std</th>\n",
       "      <th>low</th>\n",
       "      <th>peak</th>\n",
       "      <th>q25</th>\n",
       "      <th>q75</th>\n",
       "      <th>iqr</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F003-0616.wav</td>\n",
       "      <td>24</td>\n",
       "      <td>179.803922</td>\n",
       "      <td>-0.453233</td>\n",
       "      <td>-1.540090</td>\n",
       "      <td>205.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>48.533917</td>\n",
       "      <td>110.294118</td>\n",
       "      <td>240.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F000-0823.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>341.034577</td>\n",
       "      <td>-0.369143</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>385.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>164.184087</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>695.0</td>\n",
       "      <td>252.5</td>\n",
       "      <td>447.50</td>\n",
       "      <td>195.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M009-0399.wav</td>\n",
       "      <td>29</td>\n",
       "      <td>164.397933</td>\n",
       "      <td>0.870210</td>\n",
       "      <td>-0.357093</td>\n",
       "      <td>120.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>155.589327</td>\n",
       "      <td>7.540057</td>\n",
       "      <td>530.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>225.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F033-0492.wav</td>\n",
       "      <td>25</td>\n",
       "      <td>199.400000</td>\n",
       "      <td>0.323917</td>\n",
       "      <td>-1.207102</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.384288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.00</td>\n",
       "      <td>370.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M029-0430.wav</td>\n",
       "      <td>24</td>\n",
       "      <td>196.577381</td>\n",
       "      <td>0.800063</td>\n",
       "      <td>-0.598391</td>\n",
       "      <td>180.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>56.700662</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>238.75</td>\n",
       "      <td>93.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the dataset into training and test data\n",
    "Let's use 20% of the database for testing.\n",
    "\n",
    "We also need to make sure the classes(Genders) are equally distributed between the classes and separate diferent speakers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mydata_test = df[df['FileName'].str.match('F050') | df['FileName'].str.match('F049') | df['FileName'].str.match('F048') | df['FileName'].str.match('F047') | df['FileName'].str.match('F046') | \n",
    "                df['FileName'].str.match('F045') | df['FileName'].str.match('F044') | df['FileName'].str.match('F043') | df['FileName'].str.match('F042') | df['FileName'].str.match('F041') | \n",
    "                df['FileName'].str.match('M049') | df['FileName'].str.match('M048') | df['FileName'].str.match('M047') | df['FileName'].str.match('M046') | df['FileName'].str.match('M045') | \n",
    "                df['FileName'].str.match('M044') | df['FileName'].str.match('M043') | df['FileName'].str.match('M042') | df['FileName'].str.match('M041') | df['FileName'].str.match('M040')] \n",
    "\n",
    "mydata_train = df.merge(mydata_test[['FileName']], on=['FileName'], how='left', indicator=True)\n",
    "mydata_train = mydata_train[mydata_train['_merge'] == 'left_only']\n",
    "\n",
    "\n",
    "print(f'Feminine voices in the training data: {len(mydata_train.Gender)- sum(mydata_train.Gender)}')\n",
    "print(f'Masculine voices in the training data: {sum(mydata_train.Gender)}')\n",
    "print(f'Feminine voices in the test data: {len(mydata_test.Gender)- sum(mydata_test.Gender)}')\n",
    "print(f'Masculine voices in the test data: {sum(mydata_test.Gender)}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feminine voices in the training data: 40997\n",
      "Masculine voices in the training data: 40000\n",
      "Feminine voices in the test data: 10000\n",
      "Masculine voices in the test data: 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "mydata_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FileName  nobs        mean      skew  kurtosis  median   mode  \\\n",
       "0  F003-0616.wav    24  179.803922 -0.453233 -1.540090   205.0  115.0   \n",
       "1  F000-0823.wav    19  341.034577 -0.369143  0.038573   385.0  450.0   \n",
       "2  M009-0399.wav    29  164.397933  0.870210 -0.357093   120.0   15.0   \n",
       "3  F033-0492.wav    25  199.400000  0.323917 -1.207102   180.0    0.0   \n",
       "4  M029-0430.wav    24  196.577381  0.800063 -0.598391   180.0  145.0   \n",
       "\n",
       "          std         low   peak    q25     q75     iqr  Gender     _merge  \n",
       "0   48.533917  110.294118  240.0  115.0  220.00  105.00       0  left_only  \n",
       "1  164.184087   30.000000  695.0  252.5  447.50  195.00       0  left_only  \n",
       "2  155.589327    7.540057  530.0   15.0  225.00  210.00       1  left_only  \n",
       "3  188.384288    0.000000  575.0    0.0  370.00  370.00       0  left_only  \n",
       "4   56.700662  140.000000  320.0  145.0  238.75   93.75       1  left_only  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>nobs</th>\n",
       "      <th>mean</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>std</th>\n",
       "      <th>low</th>\n",
       "      <th>peak</th>\n",
       "      <th>q25</th>\n",
       "      <th>q75</th>\n",
       "      <th>iqr</th>\n",
       "      <th>Gender</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F003-0616.wav</td>\n",
       "      <td>24</td>\n",
       "      <td>179.803922</td>\n",
       "      <td>-0.453233</td>\n",
       "      <td>-1.540090</td>\n",
       "      <td>205.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>48.533917</td>\n",
       "      <td>110.294118</td>\n",
       "      <td>240.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>0</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F000-0823.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>341.034577</td>\n",
       "      <td>-0.369143</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>385.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>164.184087</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>695.0</td>\n",
       "      <td>252.5</td>\n",
       "      <td>447.50</td>\n",
       "      <td>195.00</td>\n",
       "      <td>0</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M009-0399.wav</td>\n",
       "      <td>29</td>\n",
       "      <td>164.397933</td>\n",
       "      <td>0.870210</td>\n",
       "      <td>-0.357093</td>\n",
       "      <td>120.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>155.589327</td>\n",
       "      <td>7.540057</td>\n",
       "      <td>530.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>225.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>1</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F033-0492.wav</td>\n",
       "      <td>25</td>\n",
       "      <td>199.400000</td>\n",
       "      <td>0.323917</td>\n",
       "      <td>-1.207102</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.384288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.00</td>\n",
       "      <td>370.00</td>\n",
       "      <td>0</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M029-0430.wav</td>\n",
       "      <td>24</td>\n",
       "      <td>196.577381</td>\n",
       "      <td>0.800063</td>\n",
       "      <td>-0.598391</td>\n",
       "      <td>180.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>56.700662</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>238.75</td>\n",
       "      <td>93.75</td>\n",
       "      <td>1</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "y_test = mydata_test[['Gender']].copy().values.ravel()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x_train)\n",
    "X_train = pd.DataFrame(scaler.transform(data_x_train), columns=data_x_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(data_x_test), columns=data_x_test.columns)\n",
    "pickle.dump(scaler, open('models/scaler.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "filename = 'models/CETUC_DecisionTree.sav'\n",
    "pickle.dump(tree, open(filename, 'wb'))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "#Train random forest model\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "filename = 'models/CETUC_RandomForest.sav'\n",
    "pickle.dump(forest, open(filename, 'wb'))\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "#Train gradient boosting model\n",
    "gbrt = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "filename = 'models/CETUC_GradientBoosting.sav'\n",
    "pickle.dump(gbrt, open(filename, 'wb'))\n",
    "print(\"\\nGradient Boosting\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "#Train support vector machine model\n",
    "svm = SVC().fit(X_train, y_train)\n",
    "filename = 'models/CETUC_SVM.sav'\n",
    "pickle.dump(svm, open(filename, 'wb'))\n",
    "print(\"\\nSupport Vector Machine\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svm.score(X_test, y_test)))\n",
    "\n",
    "#Train neural network model\n",
    "mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
    "filename = 'models/CETUC_MLP.sav'\n",
    "pickle.dump(mlp, open(filename, 'wb'))\n",
    "print(\"\\nMultilayer Perceptron\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.757\n",
      "\n",
      "Random Forests\n",
      "Accuracy on training set: 0.986\n",
      "Accuracy on test set: 0.785\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy on training set: 0.865\n",
      "Accuracy on test set: 0.824\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_feature_importances_mydata(model, c):\n",
    "    n_features = len(X_train.columns)\n",
    "    plt.figure(1,figsize=(18,10))\n",
    "    plt.bar(range(n_features), model.feature_importances_, align='center', color=c)\n",
    "    plt.xticks(np.arange(n_features), X_train.columns)\n",
    "    plt.ylabel(\"Variable importance\")\n",
    "    plt.xlabel(\"Independent Variable\")\n",
    "    plt.title(model.__class__.__name__)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_feature_importances_mydata(gbrt,'blue')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "NeuralNetwork = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8, activation='relu', input_shape=(12,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "NeuralNetwork.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = NeuralNetwork.fit(X_train, y_train,validation_split=0.2, epochs=100, verbose=4)\n",
    "\n",
    "test_loss, test_acc = NeuralNetwork.evaluate(X_test,  y_test, verbose=0)\n",
    "\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "metadata": {
   "interpreter": {
    "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}