{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "import asyncio\n",
    "import time\n",
    "import nest_asyncio\n",
    "import parselmouth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frequency Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "source = os.path.join(project_root, \"MLS\", \"Full_split\")\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(source, \"metainfo.csv\"))\n",
    "data = metadata[['SPEAKER','GENDER']]\n",
    "data_dict = dict(zip(data.SPEAKER, data.GENDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_frequencies(file):\n",
    "    \n",
    "    file_path = os.path.join(source, file)\n",
    "    audio_data = parselmouth.Sound(file_path)\n",
    "    audio_data = audio_data.values[0]\n",
    "    sample_rate = 22050\n",
    "\n",
    "    splited_file = file.split('_')\n",
    "    if data_dict[int(splited_file[0])] == 'F':\n",
    "        gender = 0\n",
    "    if data_dict[int(splited_file[0])] == 'M': \n",
    "        gender = 1\n",
    "\n",
    "    step = int(sample_rate/5) #3200 sampling points every 1/5 sec\n",
    "    window_frequencies = []\n",
    "\n",
    "    for i in range(0,len(audio_data),step):\n",
    "        ft = np.fft.fft(audio_data[i:i+step]) #fft returns the list N complex numbers\n",
    "        freqs = librosa.fft_frequencies(sr=sample_rate, n_fft=len(ft))\n",
    "        freqs = np.fft.fftfreq(len(ft)) #fftq tells you the frequencies associated with the coefficients\n",
    "        imax = np.argmax(np.abs(ft))\n",
    "        freq = freqs[imax]\n",
    "        freq_in_hz = abs(freq *sample_rate)\n",
    "        window_frequencies.append(freq_in_hz)\n",
    "\n",
    "    return window_frequencies, gender, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_features(count, file):\n",
    "    async with sem:\n",
    "        frequencies, gender, file_name = await get_frequencies(file)\n",
    "\n",
    "        nobs, minmax, mean, variance, skew, kurtosis =  stats.describe(frequencies)\n",
    "        median   = np.median(frequencies)\n",
    "        mode     = stats.mode(frequencies).mode[0]\n",
    "        std      = np.std(frequencies)\n",
    "        low,peak = minmax\n",
    "        q75,q25  = np.percentile(frequencies, [75 ,25])\n",
    "        iqr      = q75 - q25\n",
    "\n",
    "        features_list.append([file_name, nobs, mean, skew, kurtosis, median, mode, std, low, peak, q25, q75, iqr, gender])\n",
    "        print(f\"\\r{count}/{len(audio_files)}\", end='')\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculo de tempo de disparo\n",
    "start_time = time.time()\n",
    "\n",
    "#inicio do Loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Controle de requisições por vez\n",
    "sem = asyncio.Semaphore(600)\n",
    "\n",
    "#Array de tasks\n",
    "sents = []\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Coleta as recomendações para envio\n",
    "gender_list = []\n",
    "file_list = []\n",
    "features_list = []\n",
    "\n",
    "audio_files = os.listdir(source)\n",
    "for k, file in enumerate(audio_files):\n",
    "        if file.endswith('.wav'):       \n",
    "                sent = asyncio.ensure_future(get_features(count=k+1, file=file))\n",
    "                sents.append(sent)\n",
    " \n",
    "done, _ = loop.run_until_complete(asyncio.wait(sents))\n",
    "dataframe_features = pd.DataFrame(features_list, columns = ['FileName', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', 'Gender'])\n",
    "dataframe_features.to_csv('D:\\dev\\Speaker-Gender-Recognition\\data\\MLS_split\\Features_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "source = os.path.join(project_root, \"MLS\", \"Full_split\")\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(source, \"metainfo.csv\"))\n",
    "data = metadata[['SPEAKER','GENDER']]\n",
    "data_dict = dict(zip(data.SPEAKER, data.GENDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_MFCCs(count, file):\n",
    "    async with sem:\n",
    "\n",
    "        file_path = os.path.join(source, file)\n",
    "        audio_data, sample_rate = librosa.load(file_path)\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate)\n",
    "        mfccs_mean = list(np.mean(mfccs.T, axis= 0))\n",
    "\n",
    "        splited_file = file.split('_')\n",
    "        if data_dict[int(splited_file[0])] == 'F':\n",
    "            gender = 0\n",
    "        if data_dict[int(splited_file[0])] == 'M': \n",
    "            gender = 1\n",
    "        \n",
    "        audio_data = parselmouth.Sound(file_path)\n",
    "        audio_data = audio_data.values[0]\n",
    "        sample_rate = 22050\n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate)\n",
    "        \n",
    "        mfccs_mean = list(np.mean(mfccs.T, axis= 0))\n",
    "        \n",
    "        sample_features = mfccs_mean\n",
    "        sample_features.insert(0,str(file))\n",
    "        sample_features.append(gender)\n",
    "        \n",
    "        print(f\"\\r{count}/{len(audio_files)}\",end='')\n",
    "        features_list.append(sample_features)\n",
    "    \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculo de tempo de disparo\n",
    "start_time = time.time()\n",
    "\n",
    "#inicio do Loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Controle de requisições por vez\n",
    "sem = asyncio.Semaphore(600)\n",
    "\n",
    "#Array de tasks\n",
    "sents = []\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Coleta as recomendações para envio\n",
    "gender_list = []\n",
    "file_list = []\n",
    "features_list = []\n",
    "\n",
    "audio_files = os.listdir(source)\n",
    "for k, file in enumerate(audio_files):\n",
    "        if file.endswith('.wav'):\n",
    "                sent = asyncio.ensure_future(extract_MFCCs(count=k+1, file=file))\n",
    "                sents.append(sent)\n",
    " \n",
    "done, _ = loop.run_until_complete(asyncio.wait(sents))\n",
    "\n",
    "dataframe_features = pd.DataFrame(features_list, columns = ['FileName','MFCC_1','MFCC_2','MFCC_3','MFCC_4','MFCC_5',\n",
    "                                                            'MFCC_6','MFCC_7','MFCC_8','MFCC_9','MFCC_10','MFCC_11',\n",
    "                                                            'MFCC_12','MFCC_13','MFCC_14','MFCC_15','MFCC_16','MFCC_17',\n",
    "                                                            'MFCC_18','MFCC_19','MFCC_20','Gender'])\n",
    "dataframe_features.to_csv('D:\\dev\\Speaker-Gender-Recognition\\data\\MLS_split\\MFCCs_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "source = os.path.join(project_root, \"MLS\", \"Full_split\")\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(source, \"metainfo.csv\"))\n",
    "data = metadata[['SPEAKER','GENDER']]\n",
    "data_dict = dict(zip(data.SPEAKER, data.GENDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_F0(count, file):\n",
    "    async with sem:\n",
    "        file_path = os.path.join(source, file)\n",
    "        \n",
    "        audio_data = parselmouth.Sound(file_path)\n",
    "        pitch = audio_data.to_pitch()\n",
    "        pitch_values = pitch.selected_array['frequency']\n",
    "        \n",
    "\n",
    "        nobs_pitch, minmax_pitch, mean_pitch, variance_pitch, skew_pitch, kurtosis_pitch =  stats.describe(pitch_values)\n",
    "        median_pitch   = np.median(pitch_values)\n",
    "        mode_pitch     = stats.mode(pitch_values).mode[0]\n",
    "        std_pitch      = np.std(pitch_values)\n",
    "        low_pitch,peak_pitch = minmax_pitch\n",
    "        q75_pitch,q25_pitch  = np.percentile(pitch_values, [75 ,25])\n",
    "        iqr_pitch      = q75_pitch - q25_pitch\n",
    "        \n",
    "        splited_file = file.split('_')\n",
    "        if data_dict[int(splited_file[0])] == 'F':\n",
    "            gender = 0\n",
    "        \n",
    "        if data_dict[int(splited_file[0])] == 'M': \n",
    "            gender = 1\n",
    "        \n",
    "        \n",
    "        sample_features = [nobs_pitch, mean_pitch, skew_pitch, kurtosis_pitch, median_pitch, mode_pitch, std_pitch, low_pitch, peak_pitch, q25_pitch, q75_pitch, iqr_pitch]\n",
    "        sample_features.insert(0,str(file))\n",
    "        sample_features.append(gender)\n",
    "        \n",
    "        string = ','.join(str(item) for item in sample_features)\n",
    "        print(f\"\\r{count}/{len(audio_files)}\",end='')\n",
    "        features_list.append(sample_features)\n",
    "    \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2336/4913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\Speaker-Gender-Recognition\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3621: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "d:\\dev\\Speaker-Gender-Recognition\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4912/4913"
     ]
    }
   ],
   "source": [
    "# #Calculo de tempo de disparo\n",
    "start_time = time.time()\n",
    "\n",
    "#inicio do Loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Controle de requisições por vez\n",
    "sem = asyncio.Semaphore(600)\n",
    "\n",
    "#Array de tasks\n",
    "sents = []\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Coleta as recomendações para envio\n",
    "gender_list = []\n",
    "file_list = []\n",
    "features_list = []\n",
    "\n",
    "audio_files = os.listdir(source)\n",
    "\n",
    "for k, file in enumerate(audio_files):\n",
    "    if file.endswith('.wav'):\n",
    "        sent = asyncio.ensure_future(extract_F0(count=k+1, file=file))\n",
    "        sents.append(sent)\n",
    " \n",
    "done, _ = loop.run_until_complete(asyncio.wait(sents))\n",
    "\n",
    "dataframe_features = pd.DataFrame(features_list, columns = ['FileName', 'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch',\n",
    " 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', 'Gender'])\n",
    "\n",
    "dataframe_features.to_csv('D:\\dev\\Speaker-Gender-Recognition\\data\\MLS_split\\F0_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5486e5cd054d1e412d6aef716f8c2fbe82dbf0bdc56586f31f4b3a964d871afa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
