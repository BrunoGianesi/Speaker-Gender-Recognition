{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'Features_F0'\n",
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "df = pd.read_csv(f'{project_root}/data/CETUC/{features}_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training and test data\n",
    "Let's use 20% of the database for testing.\n",
    "\n",
    "We also need to make sure the classes(Genders) are equally distributed between the classes and separate diferent speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_test = df[df['FileName'].str.match('F050') | df['FileName'].str.match('F049') | df['FileName'].str.match('F048') | df['FileName'].str.match('F047') | df['FileName'].str.match('F046') | \n",
    "                df['FileName'].str.match('F045') | df['FileName'].str.match('F044') | df['FileName'].str.match('F043') | df['FileName'].str.match('F042') | df['FileName'].str.match('F041') | \n",
    "                df['FileName'].str.match('M049') | df['FileName'].str.match('M048') | df['FileName'].str.match('M047') | df['FileName'].str.match('M046') | df['FileName'].str.match('M045') | \n",
    "                df['FileName'].str.match('M044') | df['FileName'].str.match('M043') | df['FileName'].str.match('M042') | df['FileName'].str.match('M041') | df['FileName'].str.match('M040')] \n",
    "\n",
    "mydata_train = df.merge(mydata_test[['FileName']], on=['FileName'], how='left', indicator=True)\n",
    "mydata_train = mydata_train[mydata_train['_merge'] == 'left_only']\n",
    "mydata_train = mydata_train[~mydata_train['FileName'].str.match('F040')]\n",
    "\n",
    "\n",
    "print(f'Feminine voices in the training data: {len(mydata_train.Gender)- sum(mydata_train.Gender)}')\n",
    "print(f'Masculine voices in the training data: {sum(mydata_train.Gender)}')\n",
    "print(f'Feminine voices in the test data: {len(mydata_test.Gender)- sum(mydata_test.Gender)}')\n",
    "print(f'Masculine voices in the test data: {sum(mydata_test.Gender)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features == 'MFCCs':\n",
    "    data_x_train = mydata_train[['MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "if features == 'Features':\n",
    "    data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "if features == 'Features_MFCCs':\n",
    "    data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "if features == 'F0':\n",
    "    data_x_train = mydata_train[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "if features == 'F0_MFCCs':\n",
    "    data_x_train = mydata_train[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "if features == 'Features_F0':\n",
    "    data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "if features == 'Features_F0_MFCCs':\n",
    "    data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "    data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    y_test = mydata_test[['Gender']].copy().values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x_train)\n",
    "X_train = pd.DataFrame(scaler.transform(data_x_train), columns=data_x_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(data_x_test), columns=data_x_test.columns)\n",
    "pickle.dump(scaler, open(f'{project_root}/models/CETUC/{features}/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "filename = f'{project_root}/models/CETUC/{features}/DecisionTree.sav'\n",
    "pickle.dump(tree, open(filename, 'wb'))\n",
    "print(\"\\n--------------------------Decision Tree--------------------------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, tree.predict(X_train), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on training set:  {precision}\")\n",
    "print(f\"Recall on training set: {recall}\")\n",
    "print(f\"F1-score on training set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "    #Test\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "cm = confusion_matrix(y_test, tree.predict(X_test), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on test set:  {precision}\")\n",
    "print(f\"Recall on test set: {recall}\")\n",
    "print(f\"F1-score on test set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "\n",
    "#Train random forest model\n",
    "    #Training\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "filename = f'{project_root}/models/CETUC/{features}/RandomForest.sav'\n",
    "pickle.dump(forest, open(filename, 'wb'))\n",
    "print(\"\\n--------------------------Random Forests--------------------------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, forest.predict(X_train), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on training set:  {precision}\")\n",
    "print(f\"Recall on training set: {recall}\")\n",
    "print(f\"F1-score on training set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "    #Test\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))\n",
    "cm = confusion_matrix(y_test, forest.predict(X_test), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on test set:  {precision}\")\n",
    "print(f\"Recall on test set: {recall}\")\n",
    "print(f\"F1-score on test set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "\n",
    "#Train gradient boosting model\n",
    "gbrt = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "filename = f'{project_root}/models/CETUC/{features}/GradientBoosting.sav'\n",
    "pickle.dump(gbrt, open(filename, 'wb'))\n",
    "print(\"\\n--------------------------Gradient Boosting--------------------------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, gbrt.predict(X_train), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on training set:  {precision}\")\n",
    "print(f\"Recall on training set: {recall}\")\n",
    "print(f\"F1-score on training set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "    #Test\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
    "cm = confusion_matrix(y_test, gbrt.predict(X_test), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on test set:  {precision}\")\n",
    "print(f\"Recall on test set: {recall}\")\n",
    "print(f\"F1-score on test set: {2 * (precision * recall) / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train logistic regression model\n",
    "lgr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "filename = f'{project_root}/models/CETUC/{features}/LogisticRegression.sav'\n",
    "pickle.dump(lgr, open(filename, 'wb'))\n",
    "print(\"\\n--------------------------LogisticRegression--------------------------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(lgr.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, lgr.predict(X_train), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on training set:  {precision}\")\n",
    "print(f\"Recall on training set: {recall}\")\n",
    "print(f\"F1-score on training set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "    #Test\n",
    "print(\"Accuracy on test set: {:.3f}\".format(lgr.score(X_test, y_test)))\n",
    "cm = confusion_matrix(y_test, lgr.predict(X_test), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on test set:  {precision}\")\n",
    "print(f\"Recall on test set: {recall}\")\n",
    "print(f\"F1-score on test set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "\n",
    "#Train support vector machine model\n",
    "svm = SVC().fit(X_train, y_train)\n",
    "filename = f'{project_root}/models/CETUC/{features}/SVM.sav'\n",
    "pickle.dump(svm, open(filename, 'wb'))\n",
    "print(\"\\n--------------------------Support Vector Machine--------------------------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, svm.predict(X_train), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on training set:  {precision}\")\n",
    "print(f\"Recall on training set: {recall}\")\n",
    "print(f\"F1-score on training set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "    #Test\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svm.score(X_test, y_test)))\n",
    "cm = confusion_matrix(y_test, svm.predict(X_test), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on test set:  {precision}\")\n",
    "print(f\"Recall on test set: {recall}\")\n",
    "print(f\"F1-score on test set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "\n",
    "#Train neural network model\n",
    "mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
    "filename = f'{project_root}/models/CETUC/{features}/MLP.sav'\n",
    "pickle.dump(mlp, open(filename, 'wb'))\n",
    "print(\"\\n--------------------------Multilayer Perceptron--------------------------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, mlp.predict(X_train), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on training set:  {precision}\")\n",
    "print(f\"Recall on training set: {recall}\")\n",
    "print(f\"F1-score on training set: {2 * (precision * recall) / (precision + recall)}\")\n",
    "    #Test\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))\n",
    "cm = confusion_matrix(y_test, mlp.predict(X_test), labels=[1, 0])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "# print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Precision on test set:  {precision}\")\n",
    "print(f\"Recall on test set: {recall}\")\n",
    "print(f\"F1-score on test set: {2 * (precision * recall) / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>nobs</th>\n",
       "      <th>mean</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>std</th>\n",
       "      <th>low</th>\n",
       "      <th>peak</th>\n",
       "      <th>...</th>\n",
       "      <th>skew_pitch</th>\n",
       "      <th>kurtosis_pitch</th>\n",
       "      <th>median_pitch</th>\n",
       "      <th>mode_pitch</th>\n",
       "      <th>std_pitch</th>\n",
       "      <th>low_pitch</th>\n",
       "      <th>peak_pitch</th>\n",
       "      <th>q25_pitch</th>\n",
       "      <th>q75_pitch</th>\n",
       "      <th>iqr_pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F003-0616.wav</td>\n",
       "      <td>24</td>\n",
       "      <td>179.803922</td>\n",
       "      <td>-0.453233</td>\n",
       "      <td>-1.540090</td>\n",
       "      <td>205.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>48.533917</td>\n",
       "      <td>110.294118</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699460</td>\n",
       "      <td>-1.342911</td>\n",
       "      <td>201.211632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.416064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.632548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.797809</td>\n",
       "      <td>218.797809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F000-0823.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>341.034577</td>\n",
       "      <td>-0.369143</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>385.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>164.184087</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>695.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253664</td>\n",
       "      <td>-1.711468</td>\n",
       "      <td>169.026750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.613362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.846249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.105068</td>\n",
       "      <td>215.105068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M009-0399.wav</td>\n",
       "      <td>29</td>\n",
       "      <td>164.397933</td>\n",
       "      <td>0.870210</td>\n",
       "      <td>-0.357093</td>\n",
       "      <td>120.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>155.589327</td>\n",
       "      <td>7.540057</td>\n",
       "      <td>530.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.039580</td>\n",
       "      <td>14.240777</td>\n",
       "      <td>91.160534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.858767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>598.610675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.379987</td>\n",
       "      <td>113.379987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F033-0492.wav</td>\n",
       "      <td>25</td>\n",
       "      <td>199.400000</td>\n",
       "      <td>0.323917</td>\n",
       "      <td>-1.207102</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.384288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044067</td>\n",
       "      <td>-1.851095</td>\n",
       "      <td>150.570590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.443665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.803872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.764480</td>\n",
       "      <td>183.764480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M029-0430.wav</td>\n",
       "      <td>24</td>\n",
       "      <td>196.577381</td>\n",
       "      <td>0.800063</td>\n",
       "      <td>-0.598391</td>\n",
       "      <td>180.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>56.700662</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507444</td>\n",
       "      <td>-1.352320</td>\n",
       "      <td>117.890983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.925799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.084000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.727442</td>\n",
       "      <td>142.727442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FileName  nobs        mean      skew  kurtosis  median   mode  \\\n",
       "0  F003-0616.wav    24  179.803922 -0.453233 -1.540090   205.0  115.0   \n",
       "1  F000-0823.wav    19  341.034577 -0.369143  0.038573   385.0  450.0   \n",
       "2  M009-0399.wav    29  164.397933  0.870210 -0.357093   120.0   15.0   \n",
       "3  F033-0492.wav    25  199.400000  0.323917 -1.207102   180.0    0.0   \n",
       "4  M029-0430.wav    24  196.577381  0.800063 -0.598391   180.0  145.0   \n",
       "\n",
       "          std         low   peak  ...  skew_pitch  kurtosis_pitch  \\\n",
       "0   48.533917  110.294118  240.0  ...   -0.699460       -1.342911   \n",
       "1  164.184087   30.000000  695.0  ...   -0.253664       -1.711468   \n",
       "2  155.589327    7.540057  530.0  ...    3.039580       14.240777   \n",
       "3  188.384288    0.000000  575.0  ...   -0.044067       -1.851095   \n",
       "4   56.700662  140.000000  320.0  ...   -0.507444       -1.352320   \n",
       "\n",
       "   median_pitch  mode_pitch   std_pitch  low_pitch  peak_pitch  q25_pitch  \\\n",
       "0    201.211632         0.0   97.416064        0.0  265.632548        0.0   \n",
       "1    169.026750         0.0  101.613362        0.0  276.846249        0.0   \n",
       "2     91.160534         0.0   90.858767        0.0  598.610675        0.0   \n",
       "3    150.570590         0.0   94.443665        0.0  272.803872        0.0   \n",
       "4    117.890983         0.0   64.925799        0.0  205.084000        0.0   \n",
       "\n",
       "    q75_pitch   iqr_pitch  \n",
       "0  218.797809  218.797809  \n",
       "1  215.105068  215.105068  \n",
       "2  113.379987  113.379987  \n",
       "3  183.764480  183.764480  \n",
       "4  142.727442  142.727442  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = 'Features_F0_MFCCs'\n",
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "df = pd.read_csv(f'{project_root}/data/CETUC/{features}_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feture_selector(features, mydata_test, mydata_train):\n",
    "    if features == 'MFCCs':\n",
    "        data_x_train = mydata_train[['MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "    if features == 'Features':\n",
    "        data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "    if features == 'Features_MFCCs':\n",
    "        data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', \n",
    "                            'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', \n",
    "                            'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "    if features == 'F0':\n",
    "        data_x_train = mydata_train[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "    if features == 'F0_MFCCs':\n",
    "        data_x_train = mydata_train[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                            'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                            'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "    if features == 'Features_F0':\n",
    "        data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "            'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "            'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "\n",
    "    if features == 'Features_F0_MFCCs':\n",
    "        data_x_train = mydata_train[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "            'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                            'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_train = mydata_train[['Gender']].copy().values.ravel()\n",
    "        data_x_test = mydata_test[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
    "            'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                            'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                            'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "        y_test = mydata_test[['Gender']].copy().values.ravel()\n",
    "    return data_x_train, y_train, data_x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open(os.path.join(project_root, 'models', 'CETUC', features, 'scaler.pkl'), 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_test_score = []\n",
    "tree_test_recall = []\n",
    "tree_test_precision = []\n",
    "tree_test_f1 = []\n",
    "tree_train_score = []\n",
    "tree_train_recall = []\n",
    "tree_train_precision = []\n",
    "tree_train_f1 = []\n",
    "\n",
    "forest_test_score = []\n",
    "forest_test_recall = []\n",
    "forest_test_precision = []\n",
    "forest_test_f1 = []\n",
    "forest_train_score = []\n",
    "forest_train_recall = []\n",
    "forest_train_precision = []\n",
    "forest_train_f1 = []\n",
    "\n",
    "gbrt_test_score = []\n",
    "gbrt_test_recall = []\n",
    "gbrt_test_precision = []\n",
    "gbrt_test_f1 = []\n",
    "gbrt_train_score = []\n",
    "gbrt_train_recall = []\n",
    "gbrt_train_precision = []\n",
    "gbrt_train_f1 = []\n",
    "\n",
    "lgr_test_score = []\n",
    "lgr_test_recall = []\n",
    "lgr_test_precision = []\n",
    "lgr_test_f1 = []\n",
    "lgr_train_score = []\n",
    "lgr_train_recall = []\n",
    "lgr_train_precision = []\n",
    "lgr_train_f1 = []\n",
    "\n",
    "svm_test_score = []\n",
    "svm_test_recall = []\n",
    "svm_test_precision = []\n",
    "svm_test_f1 = []\n",
    "svm_train_score = []\n",
    "svm_train_recall = []\n",
    "svm_train_precision = []\n",
    "svm_train_f1 = []\n",
    "\n",
    "mlp_test_score = []\n",
    "mlp_test_recall = []\n",
    "mlp_test_precision = []\n",
    "mlp_test_f1 = []\n",
    "mlp_train_score = []\n",
    "mlp_train_recall = []\n",
    "mlp_train_precision = []\n",
    "mlp_train_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_crossvalidations = 5\n",
    "def process_numbers(list):\n",
    "    processed_list = []\n",
    "    for element in list:\n",
    "        if element < 10:\n",
    "            element_str = f'00{str(element)}'\n",
    "        else:\n",
    "            element_str = f'0{str(element)}'\n",
    "        processed_list.append(element_str)\n",
    "    return processed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\Speaker-Gender-Recognition\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 0\n",
      "Iteration = 1\n",
      "Iteration = 2\n",
      "Iteration = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\Speaker-Gender-Recognition\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_crossvalidations):\n",
    "\n",
    "    rlm = random.sample(range(49), 10)\n",
    "    rlf = random.sample(range(51), 10)\n",
    "    while 27 in rlf:\n",
    "        rlf = random.sample(range(51), 10)\n",
    "\n",
    "    rlm = process_numbers(rlm)\n",
    "    rlf = process_numbers(rlf)\n",
    "\n",
    "    mydata_test = df[df['FileName'].str.match(f'F{rlf[0]}') | df['FileName'].str.match(f'F{rlf[1]}') | df['FileName'].str.match(f'F{rlf[2]}') | df['FileName'].str.match(f'F{rlf[3]}') | df['FileName'].str.match(f'F{rlf[4]}') | \n",
    "                    df['FileName'].str.match(f'F{rlf[5]}') | df['FileName'].str.match(f'F{rlf[6]}') | df['FileName'].str.match(f'F{rlf[7]}') | df['FileName'].str.match(f'F{rlf[8]}') | df['FileName'].str.match(f'F{rlf[9]}') | \n",
    "                    df['FileName'].str.match(f'M{rlm[0]}') | df['FileName'].str.match(f'M{rlm[1]}') | df['FileName'].str.match(f'M{rlm[2]}') | df['FileName'].str.match(f'M{rlm[3]}') | df['FileName'].str.match(f'M{rlm[4]}') | \n",
    "                    df['FileName'].str.match(f'M{rlm[5]}') | df['FileName'].str.match(f'M{rlm[6]}') | df['FileName'].str.match(f'M{rlm[7]}') | df['FileName'].str.match(f'M{rlm[8]}') | df['FileName'].str.match(f'M{rlm[9]}')] \n",
    "\n",
    "    mydata_train = df.merge(mydata_test[['FileName']], on=['FileName'], how='left', indicator=True)\n",
    "    mydata_train = mydata_train[mydata_train['_merge'] == 'left_only']\n",
    "    # mydata_train = mydata_train[~mydata_train['FileName'].str.match('F040')]\n",
    "\n",
    "    data_x_train, y_train, data_x_test, y_test = feture_selector(features, mydata_test, mydata_train)\n",
    "    X_train = pd.DataFrame(scaler.transform(data_x_train), columns=data_x_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(data_x_test), columns=data_x_test.columns)\n",
    "\n",
    "    #Train decision tree model\n",
    "    tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    score = tree.score(X_train, y_train)\n",
    "    cm = confusion_matrix(y_train, tree.predict(X_train), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    tree_train_score.append(score)\n",
    "    tree_train_recall.append(recall)\n",
    "    tree_train_precision.append(precision)\n",
    "    tree_train_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "        #Test\n",
    "    score = tree.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, tree.predict(X_test), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    tree_test_score.append(score)\n",
    "    tree_test_recall.append(recall)\n",
    "    tree_test_precision.append(precision)\n",
    "    tree_test_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "    #Train random forest model\n",
    "        #Training\n",
    "    forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "    score = forest.score(X_train, y_train)\n",
    "    cm = confusion_matrix(y_train, forest.predict(X_train), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    forest_train_score.append(score)\n",
    "    forest_train_recall.append(recall)\n",
    "    forest_train_precision.append(precision)\n",
    "    forest_train_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "        #Test\n",
    "    score = forest.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, forest.predict(X_test), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    forest_test_score.append(score)\n",
    "    forest_test_recall.append(recall)\n",
    "    forest_test_precision.append(precision)\n",
    "    forest_test_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "    #Train gradient boosting model\n",
    "    gbrt = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "    score = gbrt.score(X_train, y_train)\n",
    "    cm = confusion_matrix(y_train, gbrt.predict(X_train), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    gbrt_train_score.append(score)\n",
    "    gbrt_train_recall.append(recall)\n",
    "    gbrt_train_precision.append(precision)\n",
    "    gbrt_train_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "        #Test\n",
    "    score = gbrt.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, gbrt.predict(X_test), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    gbrt_test_score.append(score)\n",
    "    gbrt_test_recall.append(recall)\n",
    "    gbrt_test_precision.append(precision)\n",
    "    gbrt_test_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "    #Train logistic regrassion model\n",
    "    lgr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    score = lgr.score(X_train, y_train)\n",
    "    cm = confusion_matrix(y_train, lgr.predict(X_train), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    lgr_train_score.append(score)\n",
    "    lgr_train_recall.append(recall)\n",
    "    lgr_train_precision.append(precision)\n",
    "    lgr_train_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "        #Test\n",
    "    score = lgr.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, lgr.predict(X_test), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    lgr_test_score.append(score)\n",
    "    lgr_test_recall.append(recall)\n",
    "    lgr_test_precision.append(precision)\n",
    "    lgr_test_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "    #Train support vector machine model\n",
    "        #Training\n",
    "    svm = SVC().fit(X_train, y_train)\n",
    "    score = svm.score(X_train, y_train)\n",
    "    cm = confusion_matrix(y_train, svm.predict(X_train), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    svm_train_score.append(score)\n",
    "    svm_train_recall.append(recall)\n",
    "    svm_train_precision.append(precision)\n",
    "    svm_train_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "        #Test\n",
    "    score = svm.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, svm.predict(X_test), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    svm_test_score.append(score)\n",
    "    svm_test_recall.append(recall)\n",
    "    svm_test_precision.append(precision)\n",
    "    svm_test_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "    #Train Multilayer perceptron model\n",
    "    mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
    "    score = mlp.score(X_train, y_train)\n",
    "    cm = confusion_matrix(y_train, mlp.predict(X_train), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    mlp_train_score.append(score)\n",
    "    mlp_train_recall.append(recall)\n",
    "    mlp_train_precision.append(precision)\n",
    "    mlp_train_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "        #Test\n",
    "    score = mlp.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, mlp.predict(X_test), labels=[1, 0])\n",
    "    precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    mlp_test_score.append(score)\n",
    "    mlp_test_recall.append(recall)\n",
    "    mlp_test_precision.append(precision)\n",
    "    mlp_test_f1.append(2 * (precision * recall) / (precision + recall))\n",
    "    print(f\"Iteration = {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Test Accuracy, reacall, precision and F1\n",
      "0.894\n",
      "0.853\n",
      "0.930\n",
      "0.889\n",
      "\n",
      "Decision Tree Train Accuracy, reacall, precision and F1\n",
      "1.000\n",
      "1.000\n",
      "1.000\n",
      "1.000\n",
      "\n",
      "Decision Tree Test Accuracy, reacall, precision and F1\n",
      "0.926\n",
      "0.901\n",
      "0.950\n",
      "0.924\n",
      "Random Forest Train Accuracy, reacall, precision and F1\n",
      "0.998\n",
      "0.998\n",
      "0.998\n",
      "0.998\n",
      "\n",
      "Gradient Boost Test Accuracy, reacall, precision and F1\n",
      "0.941\n",
      "0.916\n",
      "0.964\n",
      "0.939\n",
      "Gradient Boost Train Accuracy, reacall, precision and F1\n",
      "0.984\n",
      "0.983\n",
      "0.983\n",
      "0.983\n",
      "\n",
      "Logistic Regression Test Accuracy, reacall, precision and F1\n",
      "0.954\n",
      "0.934\n",
      "0.973\n",
      "0.952\n",
      "Logistic Regression Train Accuracy, reacall, precision and F1\n",
      "0.971\n",
      "0.968\n",
      "0.973\n",
      "0.970\n",
      "\n",
      "SVM Test Accuracy, reacall, precision and F1\n",
      "0.941\n",
      "0.915\n",
      "0.967\n",
      "0.939\n",
      "SVM Train Accuracy, reacall, precision and F1\n",
      "0.994\n",
      "0.994\n",
      "0.994\n",
      "0.994\n",
      "\n",
      "MLP Test Accuracy, reacall, precision and F1\n",
      "0.919\n",
      "0.898\n",
      "0.939\n",
      "0.918\n",
      "MLP Train Accuracy, reacall, precision and F1\n",
      "1.000\n",
      "1.000\n",
      "1.000\n",
      "1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDecision Tree Test Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(tree_test_score)))\n",
    "print(\"{:.3f}\".format(np.mean(tree_test_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(tree_test_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(tree_test_f1)))\n",
    "print(\"\\nDecision Tree Train Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(tree_train_score)))\n",
    "print(\"{:.3f}\".format(np.mean(tree_train_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(tree_train_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(tree_train_f1)))\n",
    "\n",
    "print(\"\\nDecision Tree Test Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(forest_test_score)))\n",
    "print(\"{:.3f}\".format(np.mean(forest_test_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(forest_test_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(forest_test_f1)))\n",
    "print(\"Random Forest Train Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(forest_train_score)))\n",
    "print(\"{:.3f}\".format(np.mean(forest_train_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(forest_train_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(forest_train_f1)))\n",
    "\n",
    "print(\"\\nGradient Boost Test Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_test_score)))\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_test_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_test_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_test_f1)))\n",
    "print(\"Gradient Boost Train Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_train_score)))\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_train_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_train_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(gbrt_train_f1)))\n",
    "\n",
    "print(\"\\nLogistic Regression Test Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(lgr_test_score)))\n",
    "print(\"{:.3f}\".format(np.mean(lgr_test_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(lgr_test_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(lgr_test_f1)))\n",
    "print(\"Logistic Regression Train Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(lgr_train_score)))\n",
    "print(\"{:.3f}\".format(np.mean(lgr_train_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(lgr_train_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(lgr_train_f1)))\n",
    "\n",
    "print(\"\\nSVM Test Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(svm_test_score)))\n",
    "print(\"{:.3f}\".format(np.mean(svm_test_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(svm_test_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(svm_test_f1)))\n",
    "print(\"SVM Train Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(svm_train_score)))\n",
    "print(\"{:.3f}\".format(np.mean(svm_train_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(svm_train_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(svm_train_f1)))\n",
    "\n",
    "print(\"\\nMLP Test Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(mlp_test_score)))\n",
    "print(\"{:.3f}\".format(np.mean(mlp_test_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(mlp_test_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(mlp_test_f1)))\n",
    "print(\"MLP Train Accuracy, reacall, precision and F1\")\n",
    "print(\"{:.3f}\".format(np.mean(mlp_train_score)))\n",
    "print(\"{:.3f}\".format(np.mean(mlp_train_recall)))\n",
    "print(\"{:.3f}\".format(np.mean(mlp_train_precision)))\n",
    "print(\"{:.3f}\".format(np.mean(mlp_train_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5486e5cd054d1e412d6aef716f8c2fbe82dbf0bdc56586f31f4b3a964d871afa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
