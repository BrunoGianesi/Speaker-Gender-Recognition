{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import nest_asyncio\n",
    "from speechpy import feature\n",
    "import aiofiles\n",
    "import time\n",
    "import parselmouth"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract frequency features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get metadata:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "source = os.path.join(project_root, \"CommonVoice\")\n",
    "\n",
    "metadata = pd.read_csv(source + \"/train.csv\", delimiter='\t')\n",
    "data = metadata[['path','gender']]\n",
    "data_male = data.loc[data['gender'] == 'male']\n",
    "data_male = data_male.sample(frac=1).reset_index(drop=True)\n",
    "data_female = data.loc[data['gender'] == 'female']\n",
    "\n",
    "data = pd.concat([data_male,data_female])\n",
    "data= data.sample(frac=1).reset_index(drop=True)\n",
    "data['path'] = data['path'].str.replace('.mp3','.wav')\n",
    "\n",
    "data_dict = dict(zip(data.path, data.gender))\n",
    "len(data_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-21-36542a20952e>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['path'] = data['path'].str.replace('.mp3','.wav')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6385"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "async def get_frequencies(count, file):\n",
    "    file_path = os.path.join(project_root,\"CommonVoice\", \"Full\", file)\n",
    "\n",
    "    if data_dict[file] == 'female':\n",
    "        gender = 0\n",
    "    if data_dict[file] == 'male': \n",
    "        gender = 1\n",
    "    \n",
    "\n",
    "    audio_data, sample_rate = librosa.load(file_path)\n",
    "    \n",
    "    print(f\"\\r{count}/{len(audio_files)}\",end='')\n",
    "\n",
    "    step = int(sample_rate/5) #3200 sampling points every 1/5 sec\n",
    "    window_frequencies = []\n",
    "\n",
    "    for i in range(0,len(audio_data),step):\n",
    "        ft = np.fft.fft(audio_data[i:i+step]) #fft returns the list N complex numbers\n",
    "        freqs = librosa.fft_frequencies(sr=16000, n_fft=len(ft))\n",
    "        freqs = np.fft.fftfreq(len(ft)) #fftq tells you the frequencies associated with the coefficients\n",
    "        imax = np.argmax(np.abs(ft))\n",
    "        freq = freqs[imax]\n",
    "        freq_in_hz = abs(freq *sample_rate)\n",
    "        window_frequencies.append(freq_in_hz)\n",
    "    return window_frequencies, gender, file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "async def get_features(count, file):\n",
    "    async with sem:\n",
    "        \n",
    "        frequencies, gender, file_name = await get_frequencies(count, file)\n",
    "\n",
    "        nobs, minmax, mean, variance, skew, kurtosis =  stats.describe(frequencies)\n",
    "        median   = np.median(frequencies)\n",
    "        mode     = stats.mode(frequencies).mode[0]\n",
    "        std      = np.std(frequencies)\n",
    "        low,peak = minmax\n",
    "        q75,q25  = np.percentile(frequencies, [75 ,25])\n",
    "        iqr      = q75 - q25\n",
    "\n",
    "        features_list.append([file_name, nobs, mean, skew, kurtosis, median, mode, std, low, peak, q25, q75, iqr, gender])\n",
    "\n",
    "        # string = ','.join(str(item) for item in features_list)\n",
    "        \n",
    "        # async with aiofiles.open('CommonVoice_Features_test.csv', mode='a') as f:\n",
    "        #     await f.write(f'\\n{string}')\n",
    "        \n",
    "\n",
    "        return nobs, mean, skew, kurtosis, median, mode, std, low, peak, q25, q75, iqr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# #Calculo de tempo de disparo\n",
    "start_time = time.time()\n",
    "\n",
    "#inicio do Loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Controle de requisições por vez\n",
    "sem = asyncio.Semaphore(2000)\n",
    "\n",
    "#Array de tasks\n",
    "sents = []\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Coleta as recomendações para envio\n",
    "gender_list = []\n",
    "file_list = []\n",
    "features_list = []\n",
    "\n",
    "\n",
    "keys = data_dict.keys()\n",
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(project_root,\"CommonVoice\", \"Full\")\n",
    "audio_files = os.listdir(file_path)\n",
    "audio_files = list(filter(lambda file: file in list(keys), audio_files))\n",
    "\n",
    "for k, file in enumerate(audio_files):\n",
    "    if file.endswith('.wav'):\n",
    "        sent = asyncio.ensure_future(get_features(count=k+1, file=file))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "done, _ = loop.run_until_complete(asyncio.wait(sents))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-17' coro=<get_features() done, defined at <ipython-input-9-de0e4f15ae2e>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-9-de0e4f15ae2e>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-8-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-21' coro=<get_features() done, defined at <ipython-input-9-de0e4f15ae2e>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-9-de0e4f15ae2e>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-8-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-18' coro=<get_features() done, defined at <ipython-input-9-de0e4f15ae2e>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-9-de0e4f15ae2e>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-8-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19' coro=<get_features() done, defined at <ipython-input-9-de0e4f15ae2e>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-9-de0e4f15ae2e>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-8-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-20' coro=<get_features() done, defined at <ipython-input-9-de0e4f15ae2e>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-9-de0e4f15ae2e>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-8-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "143/6385"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-5' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-9' coro=<get_features() done, defined at <ipython-input-4-dbf118664b25>:1> exception=TypeError(\"object tuple can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"<ipython-input-4-dbf118664b25>\", line 4, in get_features\n",
      "    frequencies, gender, file_name = await get_frequencies(count, file)\n",
      "  File \"<ipython-input-3-7c6d1dbf0c43>\", line 10, in get_frequencies\n",
      "    audio_data, sample_rate = await librosa.load(file_path)\n",
      "TypeError: object tuple can't be used in 'await' expression\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6385/6385"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Set of coroutines/Futures is empty.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5026a4b85cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     69\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/asyncio/tasks.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, loop, timeout, return_when)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"expect a list of futures, not {type(fs).__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Set of coroutines/Futures is empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_when\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIRST_EXCEPTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Invalid return_when value: {return_when}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Set of coroutines/Futures is empty."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "dataframe_features = pd.DataFrame(features_list, columns = ['FileName', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', 'Gender'])\n",
    "dataframe_features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          FileName  nobs        mean      skew   kurtosis  \\\n",
       "0     common_voice_pt_19564750.wav    23  362.391304  4.033082  15.434611   \n",
       "1     common_voice_pt_19547806.wav    18  773.611111  2.409074   3.949058   \n",
       "2     common_voice_pt_21663026.wav    26  172.834496  0.829338  -0.656130   \n",
       "3     common_voice_pt_19435786.wav    22  783.636364  2.505184   5.398855   \n",
       "4     common_voice_pt_20523845.wav    17  327.461673  0.640652  -0.846446   \n",
       "...                            ...   ...         ...       ...        ...   \n",
       "6380  common_voice_pt_20523676.wav    17  213.638144  1.001169  -0.439113   \n",
       "6381  common_voice_pt_20473567.wav    17  215.144976  0.909693  -0.649121   \n",
       "6382  common_voice_pt_19441121.wav    19  569.473684  2.016594   2.654423   \n",
       "6383  common_voice_pt_19331464.wav    21  609.934479  3.106523   8.537151   \n",
       "6384  common_voice_pt_21830948.wav    20  244.315057  0.488184  -1.412674   \n",
       "\n",
       "          median  mode          std   low    peak         q25     q75  \\\n",
       "0     190.000000   0.0   817.303187   0.0  4070.0    0.000000  350.00   \n",
       "1     230.000000   0.0  1662.819565   0.0  5575.0    0.000000  458.75   \n",
       "2     120.000000  90.0   111.624934  15.0   415.0   90.000000  267.50   \n",
       "3     357.500000   0.0  1330.222283   0.0  5525.0  102.500000  498.75   \n",
       "4     335.000000  50.0   291.286727  45.0   890.0   55.000000  480.00   \n",
       "...          ...   ...          ...   ...     ...         ...     ...   \n",
       "6380  145.000000  45.0   195.744193  45.0   640.0   50.000000  350.00   \n",
       "6381   65.000000  60.0   195.288880  60.0   605.0   60.000000  325.00   \n",
       "6382  190.000000   0.0   988.298504   0.0  3480.0    0.000000  385.00   \n",
       "6383  238.624066  95.0  1216.859150  85.0  5335.0  110.000000  350.00   \n",
       "6384  157.500000  10.0   236.058127  10.0   655.0   26.575283  495.00   \n",
       "\n",
       "             iqr  Gender  \n",
       "0     350.000000       1  \n",
       "1     458.750000       1  \n",
       "2     177.500000       1  \n",
       "3     396.250000       1  \n",
       "4     425.000000       1  \n",
       "...          ...     ...  \n",
       "6380  300.000000       1  \n",
       "6381  265.000000       1  \n",
       "6382  385.000000       1  \n",
       "6383  240.000000       1  \n",
       "6384  468.424717       1  \n",
       "\n",
       "[6385 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>nobs</th>\n",
       "      <th>mean</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>std</th>\n",
       "      <th>low</th>\n",
       "      <th>peak</th>\n",
       "      <th>q25</th>\n",
       "      <th>q75</th>\n",
       "      <th>iqr</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_pt_19564750.wav</td>\n",
       "      <td>23</td>\n",
       "      <td>362.391304</td>\n",
       "      <td>4.033082</td>\n",
       "      <td>15.434611</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>817.303187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.00</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_pt_19547806.wav</td>\n",
       "      <td>18</td>\n",
       "      <td>773.611111</td>\n",
       "      <td>2.409074</td>\n",
       "      <td>3.949058</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1662.819565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>458.75</td>\n",
       "      <td>458.750000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_pt_21663026.wav</td>\n",
       "      <td>26</td>\n",
       "      <td>172.834496</td>\n",
       "      <td>0.829338</td>\n",
       "      <td>-0.656130</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>111.624934</td>\n",
       "      <td>15.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>267.50</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_pt_19435786.wav</td>\n",
       "      <td>22</td>\n",
       "      <td>783.636364</td>\n",
       "      <td>2.505184</td>\n",
       "      <td>5.398855</td>\n",
       "      <td>357.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1330.222283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5525.0</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>498.75</td>\n",
       "      <td>396.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_pt_20523845.wav</td>\n",
       "      <td>17</td>\n",
       "      <td>327.461673</td>\n",
       "      <td>0.640652</td>\n",
       "      <td>-0.846446</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>291.286727</td>\n",
       "      <td>45.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>480.00</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6380</th>\n",
       "      <td>common_voice_pt_20523676.wav</td>\n",
       "      <td>17</td>\n",
       "      <td>213.638144</td>\n",
       "      <td>1.001169</td>\n",
       "      <td>-0.439113</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>195.744193</td>\n",
       "      <td>45.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>350.00</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>common_voice_pt_20473567.wav</td>\n",
       "      <td>17</td>\n",
       "      <td>215.144976</td>\n",
       "      <td>0.909693</td>\n",
       "      <td>-0.649121</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>195.288880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>325.00</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>common_voice_pt_19441121.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>569.473684</td>\n",
       "      <td>2.016594</td>\n",
       "      <td>2.654423</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>988.298504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>385.00</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>common_voice_pt_19331464.wav</td>\n",
       "      <td>21</td>\n",
       "      <td>609.934479</td>\n",
       "      <td>3.106523</td>\n",
       "      <td>8.537151</td>\n",
       "      <td>238.624066</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1216.859150</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5335.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>350.00</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6384</th>\n",
       "      <td>common_voice_pt_21830948.wav</td>\n",
       "      <td>20</td>\n",
       "      <td>244.315057</td>\n",
       "      <td>0.488184</td>\n",
       "      <td>-1.412674</td>\n",
       "      <td>157.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>236.058127</td>\n",
       "      <td>10.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>26.575283</td>\n",
       "      <td>495.00</td>\n",
       "      <td>468.424717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6385 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "dataframe_features.to_csv('data/CommonVoice_Features_data.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get MFCCs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Metadata"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "source = os.path.join(project_root, \"CommonVoice\")\n",
    "\n",
    "metadata = pd.read_csv(source + \"/train.csv\", delimiter='\t')\n",
    "data = metadata[['path','gender']]\n",
    "data_male = data.loc[data['gender'] == 'male']\n",
    "data_male = data_male.sample(frac=1).reset_index(drop=True)\n",
    "data_female = data.loc[data['gender'] == 'female']\n",
    "\n",
    "data = pd.concat([data_male,data_female])\n",
    "data= data.sample(frac=1).reset_index(drop=True)\n",
    "data['path'] = data['path'].str.replace('.mp3','.wav')\n",
    "\n",
    "data_dict = dict(zip(data.path, data.gender))\n",
    "len(data_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract MFCCs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "async def extract_MFCCs(count, file):\n",
    "    async with sem:\n",
    "        file_path = os.path.join(project_root,\"CommonVoice\", \"Full\", file)\n",
    "\n",
    "        if data_dict[file] == 'female':\n",
    "            gender = 0\n",
    "        if data_dict[file] == 'male': \n",
    "            gender = 1\n",
    "        \n",
    "        audio_data, sample_rate =librosa.load(file_path)\n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate)\n",
    "        \n",
    "        mfccs_mean = list(np.mean(mfccs.T, axis= 0))\n",
    "        \n",
    "        sample_features = mfccs_mean\n",
    "        sample_features.insert(0,str(file))\n",
    "        sample_features.append(gender)\n",
    "        \n",
    "        string = ','.join(str(item) for item in sample_features)\n",
    "        print(f\"\\r{count}/{len(audio_files)}\",end='')\n",
    "        async with aiofiles.open('CommonVoice_MFCCs_test.csv', mode='a') as f:\n",
    "            await f.write(f'\\n{string}')\n",
    "        #features_list.append(sample_features)\n",
    "    \n",
    "        return "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# #Calculo de tempo de disparo\n",
    "start_time = time.time()\n",
    "\n",
    "#inicio do Loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Controle de requisições por vez\n",
    "sem = asyncio.Semaphore(600)\n",
    "\n",
    "#Array de tasks\n",
    "sents = []\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Coleta as recomendações para envio\n",
    "gender_list = []\n",
    "file_list = []\n",
    "features_list = []\n",
    "\n",
    "keys = data_dict.keys()\n",
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(project_root,\"CommonVoice\", \"Full\")\n",
    "audio_files = os.listdir(file_path)\n",
    "audio_files = list(filter(lambda file: file in list(keys), audio_files))\n",
    "\n",
    "for k, file in enumerate(audio_files):\n",
    "    if file.endswith('.wav'):\n",
    "        sent = asyncio.ensure_future(extract_MFCCs(count=k+1, file=file))\n",
    "        sents.append(sent)\n",
    "    else:\n",
    "        pass\n",
    " \n",
    "done, _ = loop.run_until_complete(asyncio.wait(sents))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get F0"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract Metadata"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "source = os.path.join(project_root, \"CommonVoice\")\n",
    "\n",
    "metadata = pd.read_csv(source + \"/train.csv\", delimiter='\t')\n",
    "data = metadata[['path','gender']]\n",
    "data_male = data.loc[data['gender'] == 'male']\n",
    "data_male = data_male.sample(frac=1).reset_index(drop=True)\n",
    "data_female = data.loc[data['gender'] == 'female']\n",
    "\n",
    "data = pd.concat([data_male,data_female])\n",
    "data= data.sample(frac=1).reset_index(drop=True)\n",
    "data['path'] = data['path'].str.replace('.mp3','.wav')\n",
    "\n",
    "data_dict = dict(zip(data.path, data.gender))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-6-e20a7cf83100>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['path'] = data['path'].str.replace('.mp3','.wav')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "async def extract_F0(count, file):\n",
    "    async with sem:\n",
    "        file_path = os.path.join(project_root,\"CommonVoice\", \"Full\", file)\n",
    "\n",
    "        if data_dict[file] == 'female':\n",
    "            gender = 0\n",
    "        if data_dict[file] == 'male': \n",
    "            gender = 1\n",
    "\n",
    "        audio_data = parselmouth.Sound(file_path)\n",
    "        pitch = audio_data.to_pitch()\n",
    "        pitch_values = pitch.selected_array['frequency']\n",
    "        \n",
    "\n",
    "        nobs_pitch, minmax_pitch, mean_pitch, variance_pitch, skew_pitch, kurtosis_pitch =  stats.describe(pitch_values)\n",
    "        median_pitch   = np.median(pitch_values)\n",
    "        mode_pitch     = stats.mode(pitch_values).mode[0]\n",
    "        std_pitch      = np.std(pitch_values)\n",
    "        low_pitch,peak_pitch = minmax_pitch\n",
    "        q75_pitch,q25_pitch  = np.percentile(pitch_values, [75 ,25])\n",
    "        iqr_pitch      = q75_pitch - q25_pitch\n",
    "        \n",
    "        sample_features = [nobs_pitch, mean_pitch, skew_pitch, kurtosis_pitch, median_pitch, mode_pitch, std_pitch, low_pitch, peak_pitch, q25_pitch, q75_pitch, iqr_pitch]\n",
    "        sample_features.insert(0,str(file))\n",
    "        sample_features.append(gender)\n",
    "        \n",
    "        string = ','.join(str(item) for item in sample_features)\n",
    "        print(f\"\\r{count}/{len(audio_files)}\",end='')\n",
    "        async with aiofiles.open('CommonVoice_F0_test.csv', mode='a') as f:\n",
    "            await f.write(f'\\n{string}')\n",
    "        #features_list.append(sample_features)\n",
    "    \n",
    "        return "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# #Calculo de tempo de disparo\n",
    "start_time = time.time()\n",
    "\n",
    "#inicio do Loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Controle de requisições por vez\n",
    "sem = asyncio.Semaphore(600)\n",
    "\n",
    "#Array de tasks\n",
    "sents = []\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Coleta as recomendações para envio\n",
    "gender_list = []\n",
    "file_list = []\n",
    "features_list = []\n",
    "\n",
    "keys = data_dict.keys()\n",
    "project_root =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "file_path = os.path.join(project_root,\"CommonVoice\", \"Full\")\n",
    "audio_files = os.listdir(file_path)\n",
    "audio_files = list(filter(lambda file: file in list(keys), audio_files))\n",
    "\n",
    "for k, file in enumerate(audio_files):\n",
    "    if file.endswith('.wav'):\n",
    "        sent = asyncio.ensure_future(extract_F0(count=k+1, file=file))\n",
    "        sents.append(sent)\n",
    "    else:\n",
    "        pass\n",
    " \n",
    "done, _ = loop.run_until_complete(asyncio.wait(sents))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6385/6385"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
   }
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}