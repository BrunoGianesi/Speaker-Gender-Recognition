{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Models on CommonVoice"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "features = 'F0_MFCCs'\n",
    "\n",
    "test_MLS = pd.read_csv(f'data/CommonVoice_{features}_data.csv')\n",
    "\n",
    "test_MLS_male = test_MLS[test_MLS.Gender == 1]\n",
    "test_MLS_female = test_MLS[test_MLS.Gender == 0]\n",
    "test_MLS = pd.concat([test_MLS_male[:263], test_MLS_female])\n",
    "\n",
    "print(f'Feminine voices in the training data: {len(test_MLS.Gender)- sum(test_MLS.Gender)}')\n",
    "print(f'Masculine voices in the training data: {sum(test_MLS.Gender)}')\n",
    "print(f'Feminine voices in the test data: {len(test_MLS.Gender)- sum(test_MLS.Gender)}')\n",
    "print(f'Masculine voices in the test data: {sum(test_MLS.Gender)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feminine voices in the training data: 263\n",
      "Masculine voices in the training data: 263\n",
      "Feminine voices in the test data: 263\n",
      "Masculine voices in the test data: 263\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "if features == 'Features':\n",
    "    X_test = test_MLS[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr']].copy()\n",
    "    Y_test = test_MLS[['Gender']].copy()#.values.ravel()\n",
    "elif features == 'MFCCs':\n",
    "    X_test = test_MLS[['MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    Y_test = test_MLS[['Gender']].copy().values.ravel()\n",
    "elif features == 'Features_MFCCs':\n",
    "    X_test = test_MLS[['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    Y_test = test_MLS[['Gender']].copy().values.ravel()\n",
    "elif features == 'F0':\n",
    "    X_test = test_MLS[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch']].copy()\n",
    "    Y_test = test_MLS[['Gender']].copy().values.ravel()\n",
    "elif features == 'F0_MFCCs':\n",
    "    X_test = test_MLS[['nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
    "                        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
    "                        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']].copy()\n",
    "    Y_test = test_MLS[['Gender']].copy().values.ravel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# scaler = StandardScaler()\n",
    "scaler = pickle.load(open(f'models/CETUC_{features}_scaler.pkl', 'rb'))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataset = 'CETUC'\n",
    "\n",
    "filename = f'models/{dataset}_{features}_DecisionTree.sav'\n",
    "tree = pickle.load(open(filename, 'rb'))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, Y_test)))\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, tree.predict(X_test), labels=[1, 0])}\")\n",
    "\n",
    "filename = f'models/{dataset}_{features}_RandomForest.sav'\n",
    "forest = pickle.load(open(filename, 'rb'))\n",
    "print(\"\\nRandom Forests\")\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, Y_test)))\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, forest.predict(X_test), labels=[1, 0])}\")\n",
    "\n",
    "filename = f'models/{dataset}_{features}_GradientBoosting.sav'\n",
    "gbrt = pickle.load(open(filename, 'rb'))\n",
    "print(\"\\nGradient Boosting\")\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, Y_test)))\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, gbrt.predict(X_test), labels=[1, 0])}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Decision Tree\n",
      "Accuracy on test set: 0.690\n",
      "Confusion Matrix:\n",
      " [[216  47]\n",
      " [116 147]]\n",
      "\n",
      "Random Forests\n",
      "Accuracy on test set: 0.743\n",
      "Confusion Matrix:\n",
      " [[260   3]\n",
      " [132 131]]\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy on test set: 0.749\n",
      "Confusion Matrix:\n",
      " [[259   4]\n",
      " [128 135]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "filename = f'models/{dataset}_{features}_LogisticRegression.sav'\n",
    "lgr = pickle.load(open(filename, 'rb'))\n",
    "print(\"\\nLogisticRegression\")\n",
    "print(\"Accuracy on test set: {:.3f}\".format(lgr.score(X_test, Y_test)))\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, lgr.predict(X_test), labels=[1, 0])}\")\n",
    "\n",
    "filename = f'models/{dataset}_{features}_SVM.sav'\n",
    "svm = pickle.load(open(filename, 'rb'))\n",
    "print(\"\\nSupport Vector Machine\")\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svm.score(X_test, Y_test)))\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, svm.predict(X_test), labels=[1, 0])}\")\n",
    "\n",
    "filename = f'models/{dataset}_{features}_MLP.sav'\n",
    "mlp = pickle.load(open(filename, 'rb'))\n",
    "print(\"\\nMultilayer Perceptron\")\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, Y_test)))\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, mlp.predict(X_test), labels=[1, 0])}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "LogisticRegression\n",
      "Accuracy on test set: 0.673\n",
      "Confusion Matrix:\n",
      " [[247  16]\n",
      " [156 107]]\n",
      "\n",
      "Support Vector Machine\n",
      "Accuracy on test set: 0.740\n",
      "Confusion Matrix:\n",
      " [[260   3]\n",
      " [134 129]]\n",
      "\n",
      "Multilayer Perceptron\n",
      "Accuracy on test set: 0.768\n",
      "Confusion Matrix:\n",
      " [[254   9]\n",
      " [113 150]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "metadata": {
   "interpreter": {
    "hash": "236b1f587e00dfc797b67f0f09e861988e72f179bfc773f14c0ed9918c1370fd"
   }
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}