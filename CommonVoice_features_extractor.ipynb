{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import scipy.stats as stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frequency features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "source = os.path.join(current_path, \"CommonVoice\")\n",
    "\n",
    "metadata = pd.read_csv(source + \"/train.csv\", delimiter='\t')\n",
    "data = metadata[['path','gender']]\n",
    "data_male = data.loc[data['gender'] == 'male']\n",
    "data_male = data_male.sample(frac=1).reset_index(drop=True)\n",
    "data_male = data_male[:263]\n",
    "data_female = data.loc[data['gender'] == 'female']\n",
    "\n",
    "data = pd.concat([data_male,data_female])\n",
    "data= data.sample(frac=1).reset_index(drop=True)\n",
    "data['path'] = data['path'].str.replace('.mp3','.wav')\n",
    "\n",
    "data_dict = dict(zip(data.path, data.gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "file_path = os.path.join(current_path,\"CommonVoice\", \"Full\", \"common_voice_pt_19275113.wav\")\n",
    "audio_data, sample_rate = librosa.load(file_path)\n",
    "step = int(sample_rate/5)\n",
    "window_frequencies = []\n",
    "top_freq = []\n",
    "\n",
    "ft = np.fft.fft(audio_data)\n",
    "magnitude = np.abs(ft)\n",
    "frequency = np.linspace(0, sample_rate, len(magnitude))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(frequency[:int(len(frequency)/2)], magnitude[:int(len(frequency)/2)])\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies(files):\n",
    "    frequencies_list = []\n",
    "    gender_list = []\n",
    "    FileName_list = []\n",
    "    print(\"Extracting frequencies...\")\n",
    "    keys = data_dict.keys()\n",
    "    for k, file in enumerate(files):\n",
    "        if file.endswith('.wav') and file in keys:\n",
    "            file_path = os.path.join(current_path,\"MLS\", \"Full\", file)\n",
    "            if data_dict[file] == 'female':\n",
    "                gender = 0\n",
    "            if data_dict[file] == 'male': \n",
    "                gender = 1\n",
    "            audio_data, sample_rate = librosa.load(file_path)\n",
    "\n",
    "            step = int(sample_rate/15) #3200 sampling points every 1/5 sec\n",
    "            window_frequencies = []\n",
    "\n",
    "            for i in range(0,len(audio_data),step):\n",
    "                ft = np.fft.fft(audio_data[i:i+step]) #fft returns the list N complex numbers\n",
    "                freqs = np.fft.fftfreq(len(ft)) #fftq tells you the frequencies associated with the coefficients\n",
    "                imax = np.argmax(np.abs(ft))\n",
    "                freq = freqs[imax]\n",
    "                freq_in_hz = abs(freq *sample_rate)\n",
    "                window_frequencies.append(freq_in_hz)\n",
    "            FileName_list.append(file)\n",
    "            gender_list.append(gender)\n",
    "            frequencies_list.append(window_frequencies)\n",
    "            print(f\"\\r{k/len(files)*100:.3f}% complete\",end='')\n",
    "    return frequencies_list, gender_list, FileName_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(frequencies):\n",
    "\n",
    "  nobs, minmax, mean, variance, skew, kurtosis =  stats.describe(frequencies)\n",
    "  median   = np.median(frequencies)\n",
    "  mode     = stats.mode(frequencies).mode[0]\n",
    "  std      = np.std(frequencies)\n",
    "  low,peak = minmax\n",
    "  q75,q25  = np.percentile(frequencies, [75 ,25])\n",
    "  iqr      = q75 - q25\n",
    "  return nobs, mean, skew, kurtosis, median, mode, std, low, peak, q25, q75, iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frequencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunohonorio/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/brunohonorio/tcc/Speaker-Gender-Recognition/MLS/Full/common_voice_pt_20431674.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0m\u001b[1;32m   1184\u001b[0m                      \"Error opening {0!r}: \".format(self.name))\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/home/brunohonorio/tcc/Speaker-Gender-Recognition/MLS/Full/common_voice_pt_20431674.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6d7982622179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CommonVoice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maudio_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfrequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileName_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-1eecafa83279>\u001b[0m in \u001b[0;36mget_frequencies\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'male'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#3200 sampling points every 1/5 sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tcc/Speaker-Gender-Recognition/venv/lib/python3.8/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/brunohonorio/tcc/Speaker-Gender-Recognition/MLS/Full/common_voice_pt_20431674.wav'"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "file_path = os.path.join(current_path,\"CommonVoice\", \"Full\")\n",
    "audio_files = os.listdir(file_path)\n",
    "frequencies, gender_list, FileName_list = get_frequencies(audio_files)\n",
    "features_list = []\n",
    "for i, frequency in enumerate(frequencies):\n",
    "    nobs, mean, skew, kurtosis, median, mode, std, low, peak, q25, q75, iqr = get_features(frequency)\n",
    "    features_list.append([FileName_list[i], nobs, mean, skew, kurtosis, median, mode, std, low, peak, q25, q75, iqr, gender_list[i]])\n",
    "df = pd.DataFrame(features_list, columns = ['FileName', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr', 'Gender'])\n",
    "df.to_csv('data/Commonvoice_Features_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5  ('venv': venv)",
   "name": "pythonjvsc74a57bd05416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "5416e886b2da67312ca4f5cf753d3133e2603bbf2f07750dd1ae6cf6c6d20287"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}